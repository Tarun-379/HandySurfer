# HandySurfer
Control Subway surfer just using your right hand gestures, code made using python openCV, mediapipe, time, pyautogui liberaries.




ğŸ–ï¸ HandySurfer â€“ Gesture Controlled Actions Using Hand Tracking
Control your keyboard with hand gestures using MediaPipe, OpenCV, and PyAutoGUI. HandySurfer lets you perform actions like Jump, Roll, and Swipe Left/Right using real-time hand gestures.


âœ¨ Features
ğŸ–ï¸ Real-time hand and finger detection using MediaPipe

ğŸ® Map gestures to keyboard keys:
0 fingers: Press Down (ROLL)
4 or more fingers: Press Up (JUMP)
Right/Left wrist swipe: Press Right / Left arrow keys

âš¡ Smooth gesture-to-keyboard response
â±ï¸ Built-in swipe cooldown to prevent spamming

ğŸ› ï¸ Requirements
Install these dependencies before running the project:
pip install opencv-python mediapipe pyautogui

ğŸš€ How to Run
python gesture_control.py
Make sure your webcam is connected and working. Press ESC or Q to exit the program.

ğŸ§  How It Works
Hand Tracking: Uses MediaPipe to detect landmarks of the hand in real-time.

Gesture Detection:
Counts how many fingers are up.
Detects horizontal wrist movement for swipe gestures.
Keyboard Control: pyautogui simulates key presses based on the gesture.

ğŸ“ File Structure
ğŸ“ HandySurfer/
â”‚
â”œâ”€â”€ gesture_control.py    # Main script
â””â”€â”€ README.md             # Project documentation

âš ï¸ Notes
Thumb detection may be inaccurate for left-handed users or if the palm orientation changes quickly.
May not work well in low-light or with fast hand movements.
For swipe detection, keep wrist visible and swipe smoothly across the screen.

ğŸ“Œ To Do
 Improve thumb classification using hand label
 Add more gestures like pause/reset
 Add sound feedback
 Display FPS and hand labels

 
ğŸ§‘â€ğŸ’» Author
Tarun â€“ GitHub

Feel free to fork, contribute, or open an issue!


ğŸ“œ License
This project is open source and available under the MIT License.
